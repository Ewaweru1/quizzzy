{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-distractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqrzdPBr2zVOk7Sh6ymKfG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mcq-generator/blob/main/word_distractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GITHUB REPO - https://github.com/explosion/sense2vec\n",
        "\n",
        "# download and import Sense2Vec - to generate simialr words\n",
        "!pip install sense2vec\n",
        "from sense2vec import Sense2Vec\n",
        "\n",
        "# sentence transformer\n",
        "!pip install sentence_transformers==2.2.0\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "\n",
        "# Maximum Marginal Relevence Algorithm from KeyBERT\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "wpp_Rh7E74UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and extract pretrained vectors - Here we are using 2015 reddit comments\n",
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xf s2v_reddit_2015_md.tar.gz"
      ],
      "metadata": {
        "id": "gC_Tw7by7T3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load vectors\n",
        "s2v = Sense2Vec().from_disk(\"/content/s2v_old\")"
      ],
      "metadata": {
        "id": "ms3SNSaT9Ixw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_distractors(query, word_similarity_threshold=0.7):\n",
        "  query_al = s2v.get_best_sense(query.lower().replace(' ', '_'))\n",
        "\n",
        "  try:\n",
        "    assert query_al in s2v\n",
        "    temp = s2v.most_similar(query_al, n=20)\n",
        "    formatted_string = change_format(query_al, temp)\n",
        "    formatted_string.insert(0, query)\n",
        "    if query_al.split('|')[1] == 'CARDINAL':\n",
        "      return formatted_string[:4]\n",
        "    return filter_output(query, formatted_string)\n",
        "  except:\n",
        "    return None"
      ],
      "metadata": {
        "id": "FEhCWvd5GnDV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_output(orig, dummies):\n",
        "  ans_embedded, dis_embedded = return_embedding(orig, dummies)\n",
        "  dist = mmr(ans_embedded, dis_embedded,dummies)\n",
        "\n",
        "  filtered_dist = []\n",
        "  for d in dist:\n",
        "    filtered_dist.append(d[0])\n",
        "\n",
        "  return filtered_dist"
      ],
      "metadata": {
        "id": "GSsk-UEu53Cu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mmr(doc_embedding, word_embedding, words, top_n=4, diversity=0.9):\n",
        "  # extract similarity between words and docs\n",
        "  word_doc_similarity = cosine_similarity(word_embedding, doc_embedding)\n",
        "  word_similarity = cosine_similarity(word_embedding)\n",
        "\n",
        "  kw_idx = [np.argmax(word_doc_similarity)]\n",
        "  dist_idx = [i for i in range(len(words)) if i != kw_idx[0]]\n",
        "\n",
        "  for i in range(top_n - 1):\n",
        "    dist_similarities = word_doc_similarity[dist_idx, :]\n",
        "    target_similarities = np.max(word_similarity[dist_idx][:, kw_idx], axis=1)\n",
        "\n",
        "    # calculate MMR\n",
        "    mmr = (1 - diversity) * dist_similarities - diversity * target_similarities.reshape(-1, 1)\n",
        "    mmr_idx = dist_idx[np.argmax(mmr)]\n",
        "\n",
        "    # update kw\n",
        "    kw_idx.append(mmr_idx)\n",
        "    dist_idx.remove(mmr_idx)\n",
        "\n",
        "  return [(words[idx], round(float(word_doc_similarity.reshape(1, -1)[0][idx]), 4)) for idx in kw_idx]"
      ],
      "metadata": {
        "id": "aa2AvFDZ6q1V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_format(query, distractors):\n",
        "  output = []\n",
        "  for result in distractors:\n",
        "    res = result[0].split('|')\n",
        "    res = res[0].replace('_', ' ')\n",
        "    res = res[0].upper() + res[1:]\n",
        "    output.append(res)\n",
        "  return output"
      ],
      "metadata": {
        "id": "KpX1dhVyPF1-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_embedding(answer, distractors):\n",
        "  return sentence_model.encode([answer]), sentence_model.encode(distractors)"
      ],
      "metadata": {
        "id": "GONAoOb_5Q8J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"7\"\n",
        "results = word_distractors(query)\n",
        "random.shuffle(results)\n",
        "\n",
        "if results == None:\n",
        "  print(\"Sorry input is wrong\")\n",
        "else:\n",
        "  print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyhjjXSCONng",
        "outputId": "2cf31c45-f332-4d8f-a9ca-1a3d7ec952ed"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['8', '9', '6', '7']\n"
          ]
        }
      ]
    }
  ]
}