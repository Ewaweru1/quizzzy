{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-distractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLBowaIKR/ngJJwM/9Ti+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mcq-generator/blob/main/word_distractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Discard similar meaning words\n",
        "\n",
        "\n",
        "# GITHUB REPO - https://github.com/explosion/sense2vec\n",
        "\n",
        "# download and import Sense2Vec\n",
        "!pip install sense2vec\n",
        "from sense2vec import Sense2Vec"
      ],
      "metadata": {
        "id": "wpp_Rh7E74UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and extract pretrained vectors - Here we are using 2015 reddit comments\n",
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xf s2v_reddit_2015_md.tar.gz"
      ],
      "metadata": {
        "id": "gC_Tw7by7T3J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load vectors\n",
        "s2v = Sense2Vec().from_disk(\"/content/s2v_old\")"
      ],
      "metadata": {
        "id": "ms3SNSaT9Ixw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_distractors(query):\n",
        "  # TAG - NOUN, CARDINAL, NUM, PROPN, VERB\n",
        "  query = query.lower()\n",
        "  query = query.replace(' ', '_')\n",
        "  query = s2v.get_best_sense(query)\n",
        "\n",
        "  if query in s2v:\n",
        "    return s2v.most_similar(query, n=4)\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "FEhCWvd5GnDV"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_format(distractors):\n",
        "  output = []\n",
        "  for result in distractors:\n",
        "    res = result[0].split('|')\n",
        "    res = res[0].replace('_', ' ')\n",
        "    res = res[0].upper() + res[1:]\n",
        "    output.append(res)\n",
        "  return output"
      ],
      "metadata": {
        "id": "KpX1dhVyPF1-"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = change_format(word_distractors(\"1000\"))\n",
        "print(results)"
      ],
      "metadata": {
        "id": "WyhjjXSCONng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u9k5eiBdS7nO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}