{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-distractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvvHOSagAASvZITcpRitt3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mcq-generator/blob/base-dev/false_ans_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sense2vec\n",
        "!pip install sentence_transformers==2.2.0"
      ],
      "metadata": {
        "id": "75Tl6xpDEfdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sense2vec import Sense2Vec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "wpp_Rh7E74UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_model = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "\n",
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xf s2v_reddit_2015_md.tar.gz"
      ],
      "metadata": {
        "id": "gC_Tw7by7T3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s2v = Sense2Vec().from_disk(\"/content/s2v_old\")"
      ],
      "metadata": {
        "id": "ms3SNSaT9Ixw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## HELPER FUNCTIONS FOR FALSE ANSWERS\n",
        "# generate false answers from correct answer \n",
        "def false_answers(query):\n",
        "  # get the best sense for given word (like NOUN, PRONOUN, VERB...)\n",
        "  query_al = s2v.get_best_sense(query.lower().replace(' ', '_'))\n",
        "\n",
        "  # sometimes word won't be in sense2vec in that case we can't produce any output -- ##### TODO DO: DROP THAT QUESTION\n",
        "  try:\n",
        "    assert query_al in s2v\n",
        "    # get most similar 20 words (if any)\n",
        "    temp = s2v.most_similar(query_al, n=20)\n",
        "    formatted_string = change_format(query_al, temp)\n",
        "    formatted_string.insert(0, query)\n",
        "    # if answers are numbers then we don't need to filter \n",
        "    if query_al.split('|')[1] == 'CARDINAL':\n",
        "      return formatted_string[:4]\n",
        "    # else filter because sometimes similar words will be US, U.S, USA, AMERICA.. bt all are same no?\n",
        "    return filter_output(query, formatted_string)\n",
        "  except:\n",
        "    return None\n",
        "\n",
        "# change s2v format to fair readable form\n",
        "def change_format(query, distractors):\n",
        "  output = []\n",
        "  for result in distractors:\n",
        "    res = result[0].split('|')\n",
        "    res = res[0].replace('_', ' ')\n",
        "    res = res[0].upper() + res[1:]\n",
        "    output.append(res)\n",
        "  return output\n",
        "\n",
        "# generate embeddings \n",
        "def return_embedding(answer, distractors):\n",
        "  return sentence_model.encode([answer]), sentence_model.encode(distractors)\n",
        "\n",
        "# filter false answers \n",
        "def filter_output(orig, dummies):\n",
        "  ans_embedded, dis_embedded = return_embedding(orig, dummies)\n",
        "  # filter using MMMR \n",
        "  dist = mmr(ans_embedded, dis_embedded,dummies)\n",
        "\n",
        "  filtered_dist = []\n",
        "  for d in dist:\n",
        "    # 0 -> word, 1 -> confidence / probability\n",
        "    filtered_dist.append(d[0])\n",
        "\n",
        "  return filtered_dist\n",
        "\n",
        "# Mdicersity using MR - Maximal Marginal Relevence\n",
        "def mmr(doc_embedding, word_embedding, words, top_n=4, diversity=0.9):\n",
        "  # extract similarity between words and docs\n",
        "  word_doc_similarity = cosine_similarity(word_embedding, doc_embedding)\n",
        "  word_similarity = cosine_similarity(word_embedding)\n",
        "  \n",
        "  kw_idx = [np.argmax(word_doc_similarity)]\n",
        "  dist_idx = [i for i in range(len(words)) if i != kw_idx[0]]\n",
        "\n",
        "  for i in range(top_n - 1):\n",
        "    dist_similarities = word_doc_similarity[dist_idx, :]\n",
        "    target_similarities = np.max(word_similarity[dist_idx][:, kw_idx], axis=1)\n",
        "\n",
        "    # calculate MMR\n",
        "    mmr = (1 - diversity) * dist_similarities - diversity * target_similarities.reshape(-1, 1)\n",
        "    mmr_idx = dist_idx[np.argmax(mmr)]\n",
        "\n",
        "    # update kw\n",
        "    kw_idx.append(mmr_idx)\n",
        "    dist_idx.remove(mmr_idx)\n",
        "\n",
        "  return [(words[idx], round(float(word_doc_similarity.reshape(1, -1)[0][idx]), 4)) for idx in kw_idx]"
      ],
      "metadata": {
        "id": "FEhCWvd5GnDV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MAIN\n",
        "query = \"7\"\n",
        "results = false_answers(query)\n",
        "random.shuffle(results)\n",
        "\n",
        "if results == None:\n",
        "  print(\"Sorry input is wrong\")\n",
        "else:\n",
        "  print(results)"
      ],
      "metadata": {
        "id": "WyhjjXSCONng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}