{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstractive-text-summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMU3bWO85Vsmk9WKyvU7nqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mcq-generator/blob/main/summarize-extract-genQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RZ71-vZKkARx"
      },
      "outputs": [],
      "source": [
        "# TODO : OPTIMIZEEEEEE\n",
        "# TODO : RUN MULTI TEXT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE BATCH OF TEXTS"
      ],
      "metadata": {
        "id": "0Xe73sHTopJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DONT FORGET TO CHANGE TO CUDA VERSION\n",
        "# !pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio==0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip3 install transformers==4.15.0    # only this ver works with FastT5\n",
        "!pip3 install SentencePiece\n",
        "!pip3 install git+https://github.com/boudinfl/pke.git\n",
        "# FAST T5\n",
        "!pip3 install fastt5"
      ],
      "metadata": {
        "id": "Mc2Cy2Kskuzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pke\n",
        "import string\n",
        "import re\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-vZ_gitSlVZF",
        "outputId": "141c2bd2-d8b6-4c6e-f59a-dc3804a4e265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu1t-Zv7TyIi",
        "outputId": "d88e9827-d3b3-4165-8b8f-dfcc4c894213"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastT5 import get_onnx_model, get_onnx_runtime_sessions, OnnxT5 \n",
        "from transformers import AutoTokenizer\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# summarize\n",
        "model_path = '/content/gdrive/MyDrive/mcq-gen/t5-summarize'\n",
        "model_name = \"t5-large\"\n",
        "encoder_path = os.path.join(model_path, f\"{model_name}-encoder-quantized.onnx\")\n",
        "decoder_path = os.path.join(model_path, f\"{model_name}-decoder-quantized.onnx\")\n",
        "init_decoder_path = os.path.join(model_path, f\"{model_name}-init-decoder-quantized.onnx\")\n",
        "\n",
        "model_sessions = get_onnx_runtime_sessions((encoder_path,decoder_path,init_decoder_path))\n",
        "sum_model = OnnxT5(model_path, model_sessions)\n",
        "sum_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# que model\n",
        "model_path = '/content/gdrive/MyDrive/mcq-gen/t5-question'\n",
        "model_name = 't5_squad_v1'\n",
        "encoder_path = os.path.join(model_path, f\"{model_name}-encoder-quantized.onnx\")\n",
        "decoder_path = os.path.join(model_path, f\"{model_name}-decoder-quantized.onnx\")\n",
        "init_decoder_path = os.path.join(model_path, f\"{model_name}-init-decoder-quantized.onnx\")\n",
        "\n",
        "model_sessions = get_onnx_runtime_sessions((encoder_path,decoder_path,init_decoder_path))\n",
        "q_model = OnnxT5(model_path, model_sessions)\n",
        "q_tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "bTpj4BtffXsm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_bulk_text(text):\n",
        "  text = temp_pre(text)\n",
        "  # https://huggingface.co/docs/transformers/preprocessing  - Tokenize\n",
        "  encode = sum_tokenizer.encode_plus(\"summarize: \" + text, return_tensors='pt', max_length=512, pad_to_max_length=False, truncation=True)\n",
        "  return encode[\"input_ids\"], encode[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "bO_R5WSmod0q"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def temp_pre(text):\n",
        "  text = text.strip()\n",
        "  text = re.sub('[\\u2010-\\u2013]', '-', text)\n",
        "  text = re.sub('[^a-zA-Z0-9\\.,-?]', ' ', text)\n",
        "  text = re.sub(' {2,}', ' ', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "3v2ZAekno8bw"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_text = \"\"\"\n",
        " Regardless of the kind of service, cloud computing services provide users with a series of functions including:\n",
        "\n",
        "    Email\n",
        "    Storage, backup, and data retrieval\n",
        "    Creating and testing apps\n",
        "    Analyzing data\n",
        "    Audio and video streaming\n",
        "    Delivering software on demand\n",
        "\n",
        "Cloud computing is still a fairly new service but is being used by a number of different organizations from big corporations to small businesses, nonprofits to government agencies, and even individual consumers. \n",
        "\"\"\"\n",
        "\n",
        "# 1)\n",
        "\n",
        "# Centralized DBMS architecture, It means files are stored in a single location and it is maintained from only that location. It is usually used by universities, companies and banks.\n",
        "# Advantages of Centralized DBMS architecture, \n",
        "# The data integrity is increased. So, the data is accurate and consistent.\n",
        "# Since all data in one place, data security is increased.\n",
        "# It is cheaper as it requires less power and maintenance.\n",
        "# Disadvantages of Centralized DBMS architecture,\n",
        "# Lot of data access traffic which may bottleneck in some situations.\n",
        "# If multiple users try to access it simultaneously this may reduce the efficiency of the system.\n",
        "# There is no database recovery measure when system failure occurs, so all data will be lost.\n",
        "# Since all data is centralized, it takes more time to access it and search. And if the network is slow, then it takes even more time.\n",
        "\n"
      ],
      "metadata": {
        "id": "FWAR6gB_pPsg"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_text"
      ],
      "metadata": {
        "id": "U0PIL0XapzJB",
        "outputId": "075c080f-2e49-40a2-a1ed-fe87108ee9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n•\\tGraph DBMS – Uses graph structure for semantic queries. Data is stored in the form of nodes, edges and properties. \\nImportance, \\n\\uf0a7\\tAdds more detail to data.\\n\\n•\\tER DBMS – In simple RDBMS implementation a relationship between entities is implemented by storing the primary key of one entity as a foreign key in table of another entity.\\nImportance,\\n\\uf0a7\\tCreates relationship between entities between tables.\\n\\n•\\tDocument DBMS – NoSQL databases storing database in document form. Each document represents data, its relationship between other data elements and attributes of data.\\nImportance,\\n\\uf0a7\\tAmazing document storage capability and as its NoSQL, it provides fasters mechanism to store and search documents.\\n\\n•\\tNoSQL DBMS – Database that don’t use SQL. \\nImportance,\\n\\uf0a7\\tIt doesn’t have predefined schemas so its best for rapidly changing development environments.\\n\\uf0a7\\tAllows developers to make changes on the fly without affecting applications.\\n\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_pre(full_text)"
      ],
      "metadata": {
        "id": "4DlWabOQpJ27",
        "outputId": "68f4d35f-781a-4cb2-8bf9-82c6d23c53e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Regardless of the kind of service, cloud computing services provide users with a series of functions including: Email Storage, backup, and data retrieval Creating and testing apps Analyzing data Audio and video streaming Delivering software on demand Cloud computing is still a fairly new service but is being used by a number of different organizations from big corporations to small businesses, nonprofits to government agencies, and even individual consumers. Cloud can be cloud / on device.'"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_summary(text):\n",
        "  output = \"\"\n",
        "\n",
        "  for x in sent_tokenize(text):\n",
        "    x = x.capitalize()\n",
        "    output += \" \" + x\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "tUkxLqEpxtvz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "  input_tokens_ids, attention_mask = preprocess_bulk_text(text)\n",
        "  summary_encoded = sum_model.generate(input_ids=input_tokens_ids, \n",
        "                                   attention_mask=attention_mask,\n",
        "                                   num_beams=3,\n",
        "                                   num_return_sequences=1,\n",
        "                                   no_repeat_ngram_size=2, \n",
        "                                   max_length=300, \n",
        "                                   early_stopping=True)\n",
        "  # decode summarized token\n",
        "  output = sum_tokenizer.decode(summary_encoded[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "  return postprocess_summary(output)"
      ],
      "metadata": {
        "id": "8LCkFuQeiBSq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(text, kw_pop):\n",
        "  ex = pke.unsupervised.MultipartiteRank()\n",
        "  ex.load_document(text)   \n",
        "\n",
        "  pos = {'PROPN','NOUN'}\n",
        "  stoplist = list(string.punctuation) \n",
        "  stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "  stoplist += stopwords.words('english')\n",
        "  ex.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "\n",
        "  ex.candidate_weighting(alpha=1.1, threshold=0.75, method='average')\n",
        "\n",
        "  kw = ex.get_n_best(n=kw_pop)\n",
        "\n",
        "  kw_ls = []\n",
        "\n",
        "  for i in kw:\n",
        "    kw_ls.append(i[0])\n",
        "\n",
        "  return kw_ls"
      ],
      "metadata": {
        "id": "4UJu2CGRpiBO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_keywords(original, summarized, kw_pop=10):\n",
        "  orig_ls = extract_keywords(original, kw_pop)\n",
        "  sum_ls = extract_keywords(summarized, kw_pop)\n",
        "\n",
        "  orig_ls = set(orig_ls)\n",
        "  return list(orig_ls.intersection(sum_ls))"
      ],
      "metadata": {
        "id": "2vUS8makp5dG"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full_text = \"\"\"\n",
        "# Elon Musk has shown again he can influence the digital currency market with just his tweets. After saying that his electric vehicle-making company\n",
        "# Tesla will not accept payments in Bitcoin because of environmental concerns, he tweeted that he was working with developers of Dogecoin to improve\n",
        "# system transaction efficiency. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low, while Dogecoin\n",
        "# rallied by about 20 percent. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin.  In a recent tweet,\n",
        "# Musk put out a statement from Tesla that it was “concerned” about the rapidly increasing use of fossil fuels for Bitcoin (price in India) mining and\n",
        "# transaction, and hence was suspending vehicle purchases using the cryptocurrency.  A day later he again tweeted saying, “To be clear, I strongly\n",
        "# believe in crypto, but it can't drive a massive increase in fossil fuel use, especially coal”.  It triggered a downward spiral for Bitcoin value but\n",
        "# the cryptocurrency has stabilised since.   A number of Twitter users welcomed Musk's statement. One of them said it's time people started realising\n",
        "# that Dogecoin “is here to stay” and another referred to Musk's previous assertion that crypto could become the world's future currency.\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "summary = summarize(full_text)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "OhtSNJoYy9r2",
        "outputId": "38f398cd-640c-465b-aa84-2d26c388004f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Cloud computing services provide users with a series of functions including: email storage, backup, and data retrieval creating and testing apps analyzing data audio and video streaming delivering software on demand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_kw = filter_keywords(full_text, summary)"
      ],
      "metadata": {
        "id": "63Mmv08AnxJG"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_kw"
      ],
      "metadata": {
        "id": "9v3ihvU7toZy",
        "outputId": "8540f535-e1bb-4f9d-cdb9-b02fb6cc6767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['series', 'users', 'backup']"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_summary(context, answer):\n",
        "  text = \"context: {} answer: {}\".format(context, answer)\n",
        "  # https://huggingface.co/docs/transformers/preprocessing  - Tokenize\n",
        "  encode = q_tokenizer.encode_plus(text, return_tensors='pt', max_length = 382, pad_to_max_length=False, truncation=True)\n",
        "  return encode[\"input_ids\"], encode[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "XjZQKLdP6tHG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_question(context, answer):\n",
        "  input_tokens_ids, attention_mask = preprocess_summary(context, answer)\n",
        "\n",
        "  question_encoded = q_model.generate(input_ids=input_tokens_ids, \n",
        "                                             attention_mask=attention_mask,\n",
        "                                             num_beams=5,\n",
        "                                             no_repeat_ngram_size=2, \n",
        "                                             max_length=72, \n",
        "                                             early_stopping=True)\n",
        "  # decode summarized token\n",
        "  output = q_tokenizer.decode(question_encoded[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "  output = output.replace(\"question: \", \"\")\n",
        "  output = output.strip()\n",
        "  return output"
      ],
      "metadata": {
        "id": "vbrnFDvjRcT4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_question1(answer):\n",
        "  input_tokens_ids, attention_mask = preprocess_summary(summary, answer)\n",
        "\n",
        "  question_encoded = q_model.generate(input_ids=input_tokens_ids, \n",
        "                                             attention_mask=attention_mask,\n",
        "                                             num_beams=5,\n",
        "                                             no_repeat_ngram_size=2, \n",
        "                                             max_length=72, \n",
        "                                             early_stopping=True)\n",
        "  # decode summarized token\n",
        "  output = q_tokenizer.decode(question_encoded[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "  output = output.replace(\"question: \", \"\")\n",
        "  output = output.strip()\n",
        "  return output"
      ],
      "metadata": {
        "id": "EC8XYQo3XHo2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "mDWiyIX5TWGM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = time.time()\n",
        "for kw in filtered_kw:\n",
        "  print(gen_question(summary, kw))\n",
        "  print(kw)\n",
        "e = time.time()\n",
        "\n",
        "print(e-s)"
      ],
      "metadata": {
        "id": "0cqCVhRxYBzj",
        "outputId": "85cf74c1-841f-4cac-e403-834017aedebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloud computing services provide users with how many functions?\n",
            "series\n",
            "Who can use cloud computing services?\n",
            "users\n",
            "Along with email storage and data retrieval, what function does the cloud provide?\n",
            "backup\n",
            "3.97314453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kw_np = np.array(filtered_kw)"
      ],
      "metadata": {
        "id": "6nvqU3O8TfcS"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = time.time()\n",
        "fun = np.vectorize(gen_question1)\n",
        "\n",
        "print(fun(kw_np))\n",
        "e = time.time()"
      ],
      "metadata": {
        "id": "MhcRM7TnTwC6",
        "outputId": "7d469017-adf9-4dd0-834b-9c07d7194a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What means files are stored in a single location and it is maintained from only that location?'\n",
            " 'Centralized dbms architecture requires less of what?'\n",
            " 'What is stored in a single location?'\n",
            " 'What will be lost if a system fails?'\n",
            " 'What are the advantages of centralized dbms?'\n",
            " 'How much data access traffic does centralized dbms avoid?'\n",
            " 'When is there no database recovery measure?'\n",
            " 'What is improved by using centralized dbms?'\n",
            " 'What is a bottleneck of data access traffic?'\n",
            " 'Where are files stored in centralized dbms?'\n",
            " 'What is a bottleneck of centralized dbms?'\n",
            " 'What is increased with centralized dbms?'\n",
            " 'What does centralized dbms not provide when a system fails?'\n",
            " 'If a centralized dbms architecture is slow, then it takes more time to access and search data.'\n",
            " 'If the network is slow, what does it take to access and search?'\n",
            " 'Centralized dbms requires less power and what else?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(e-s)"
      ],
      "metadata": {
        "id": "P8Lj05oRWrRT",
        "outputId": "429fc9be-61bd-4018-b050-1eb5c3ed1d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.54746103286743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E4DtgAa_W8Kc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}